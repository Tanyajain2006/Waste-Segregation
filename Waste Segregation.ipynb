{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing neccessary library\n",
    "\n",
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vanya\\OneDrive\\Desktop\\VANYA\\IEEE_Open_Source\\Waste-Segregation\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\vanya\\onedrive\\desktop\\vanya\\ieee_open_source\\waste-segregation\\venv\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\vanya\\onedrive\\desktop\\vanya\\ieee_open_source\\waste-segregation\\venv\\lib\\site-packages (from scipy) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vanya\\OneDrive\\Desktop\\VANYA\\IEEE_Open_Source\\Waste-Segregation\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.3\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting ub ImageDataGenerator\n",
    "train_data = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14165 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading Training Data\n",
    "train = train_data.flow_from_directory(\n",
    "    \"C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/Dataset/train\",\n",
    "    target_size = (200, 200),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading testing data\n",
    "test = test_data.flow_from_directory(\n",
    "    \"C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/Dataset/val\",\n",
    "    target_size = (200, 200),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(64, (2, 2), activation = 'relu', input_shape = (200, 200, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(train.num_classes, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "443/443 [==============================] - 667s 2s/step - loss: 1.3445 - accuracy: 0.9014 - val_loss: 0.3575 - val_accuracy: 0.8626\n",
      "Epoch 2/5\n",
      "443/443 [==============================] - 935s 2s/step - loss: 0.1768 - accuracy: 0.9300 - val_loss: 0.4197 - val_accuracy: 0.8393\n",
      "Epoch 3/5\n",
      "443/443 [==============================] - 867s 2s/step - loss: 0.1676 - accuracy: 0.9338 - val_loss: 0.3210 - val_accuracy: 0.8643\n",
      "Epoch 4/5\n",
      "443/443 [==============================] - 726s 2s/step - loss: 0.1606 - accuracy: 0.9365 - val_loss: 0.3942 - val_accuracy: 0.8551\n",
      "Epoch 5/5\n",
      "443/443 [==============================] - 634s 1s/step - loss: 0.1552 - accuracy: 0.9364 - val_loss: 0.3551 - val_accuracy: 0.8709\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(\n",
    "    train,\n",
    "    epochs = 5,\n",
    "    validation_data = test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 9s 239ms/step - loss: 0.3550 - accuracy: 0.8708\n",
      "Test Loss: 0.35496413707733154\n",
      "Test accuracy: 0.8707770109176636\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test, steps = test.samples // batch_size)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('waste_segregation_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(img_path):\n",
    "    img = image.load_img(\n",
    "        img_path,\n",
    "        target_size = (200, 200)\n",
    "    )\n",
    "    array = image.img_to_array(img) / 255.0\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    prediction = model.predict(array)\n",
    "\n",
    "    if prediction[0][0] >= 0.5:\n",
    "        return 'recyclable'\n",
    "    else:\n",
    "        return 'organic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 528ms/step\n",
      "Image: C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash1.jpg, Category: organic\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Image: C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash2.jpg, Category: organic\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Image: C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash3.jpg, Category: recyclable\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Image: C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash4.jpg, Category: recyclable\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Image: C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash5.jpg, Category: recyclable\n"
     ]
    }
   ],
   "source": [
    "# Test with specific image paths\n",
    "new_image = [\n",
    "    \"C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash1.jpg\",\n",
    "    \"C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash2.jpg\",\n",
    "    \"C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash3.jpg\",\n",
    "    \"C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash4.jpg\",\n",
    "    \"C:/Users/vanya/OneDrive/Desktop/VANYA/IEEE_Open_Source/ClassifyImages/trash5.jpg\"\n",
    "]\n",
    "\n",
    "for img_path in new_image:\n",
    "    category = classify(img_path)\n",
    "    print(f\"Image: {img_path}, Category: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"waste_segregation_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    img = cv2.resize(frame, (200, 200))  # same size as training\n",
    "    img = img.astype(\"float32\") / 255.0  # normalize\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vanya\\onedrive\\desktop\\vanya\\ieee_open_source\\waste-segregation\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\vanya\\onedrive\\desktop\\vanya\\ieee_open_source\\waste-segregation\\venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vanya\\onedrive\\desktop\\vanya\\ieee_open_source\\waste-segregation\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vanya\\onedrive\\desktop\\vanya\\ieee_open_source\\waste-segregation\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-2.3.3 pytz-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vanya\\OneDrive\\Desktop\\VANYA\\IEEE_Open_Source\\Waste-Segregation\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"live_predictions.csv\"\n",
    "results_df = pd.DataFrame(columns=[\"Timestamp\", \"Predicted_Class\", \"Confidence\"])\n",
    "results_df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live classification... Press 'q' to quit.\n",
      " Live predictions saved to live_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)  # 0 = default camera\n",
    "\n",
    "print(\"Starting live classification... Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = cv2.resize(frame, (200, 200))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Make prediction\n",
    "    preds = model.predict(img_array, verbose=0)\n",
    "    pred_class = labels[np.argmax(preds)]\n",
    "    confidence = np.max(preds) * 100\n",
    "\n",
    "    # Display prediction on frame\n",
    "    text = f\"{pred_class}: {confidence:.2f}%\"\n",
    "    cv2.putText(frame, text, (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Show video window\n",
    "    cv2.imshow(\"Live Waste Classification\", frame)\n",
    "\n",
    "    # Save prediction result with timestamp to CSV\n",
    "    new_entry = pd.DataFrame({\n",
    "        \"Timestamp\": [time.strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
    "        \"Predicted_Class\": [pred_class],\n",
    "        \"Confidence\": [round(confidence, 2)]\n",
    "    })\n",
    "    new_entry.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\" Live predictions saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
